{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(\"../data/zonal-means-aggregate-200910-201912.csv\")\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=full_df, x=\"month\", hue=\"outbreak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=full_df, x=\"year\", hue=\"outbreak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = full_df[\"outbreak\"].value_counts()\n",
    "print(\"Class Distribution:\\n\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename target columns to focus on oversample of minority class\n",
    "X = full_df.drop(columns=[\"outbreak\"])\n",
    "y = full_df[\"outbreak\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE algorithm for treating imbalanced datasets cannot deal with missing values (NaNs) for Feature columns, so we need to impute the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SimpleImputer to impute missing values (replace NaN with the mean of the column)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the result back to a DataFrame (optional)\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SMOTE to the training data with a 1:10 ratio\n",
    "smote = SMOTE(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new class distribution after SMOTE\n",
    "resampled_class_counts = pd.Series(y_resampled).value_counts()\n",
    "print(\"\\nClass Distribution after SMOTE:\\n\", resampled_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train your machine learning model on the balanced dataset\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"\\nModel Accuracy on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your machine learning model on the balanced dataset (already done in the previous code)\n",
    "\n",
    "# Get feature importances from the trained RandomForestClassifier\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding importances\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X_imputed.columns, \"Importance\": feature_importances}\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    by=\"Importance\", ascending=False\n",
    ")\n",
    "\n",
    "# Print the top N most influential features (adjust N as needed)\n",
    "top_n_features = 10  # Change this to the number of top features you want to display\n",
    "print(f\"Top {top_n_features} Most Influential Features:\")\n",
    "print(feature_importance_df.head(top_n_features))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
