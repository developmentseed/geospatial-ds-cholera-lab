{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cholera dataset\n",
    "In this notebook we'll explore cholera outbreak data (2010-2019) for sub-Saharan Africa available [here](https://github.com/HopkinsIDD/cholera_outbreaks_ssa/blob/main/reference_data/outbreak_data.csv). Further metadata about this dataset can be found in the repo's [README.md](https://github.com/HopkinsIDD/cholera_outbreaks_ssa) file. This dataset is sourced from [Zheng et al. (2022)](https://www.sciencedirect.com/science/article/pii/S1201971222003034), but for the purposes of this work, we'll use this dataset purely as a source of outbreak data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "hv.extension(\"bokeh\")  # pyright: ignore\n",
    "\n",
    "%output widgets='live' holomap='scrubber'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data = pd.read_csv(\"data/outbreak_data.csv\")\n",
    "cholera_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick examination of the dataset\n",
    "\n",
    "Looking at a summary of the dataset, columns, datatypes and missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that the majority of all columns do not have missing data, with the exception of `total_deaths`, `cfr` (the case fatality rate of an outbreak) and `total_confirmed_cases.` This makes sense as not all outbreaks will have confirmed deaths, and some suspected outbreaks may not have any confirmed cases. Below, we'll look at these missing values a bit closer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data[cholera_data.isnull().any(1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preparation\n",
    "Some pre-processing of the cholera data, to make it easier to work with other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country column is not clean\n",
    "\n",
    "# cholera_data = cholera_data.rename(columns={\"country\": \"ISO3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data_admin2 = cholera_data.query(\"spatial_scale == 'admin2'\")\n",
    "cholera_data_admin2 = pd.concat(\n",
    "    [\n",
    "        cholera_data_admin2[\"location\"]\n",
    "        # Split `location` parts into columns\n",
    "        .str.split(\"::\", expand=True)\n",
    "        .drop([0], axis=1)  # Drop WHO region column\n",
    "        .rename({1: \"ISO3\", 2: \"admin1\", 3: \"admin2\"}, axis=1)\n",
    "        .apply(lambda column: column.str.upper().str.removesuffix(\"HEALTHDISTRICT\")),\n",
    "        cholera_data_admin2.drop([\"who_region\", \"country\", \"location\"], axis=1),\n",
    "    ],\n",
    "    axis=1,\n",
    ").sort_values(by=[\"ISO3\", \"admin1\", \"admin2\"])\n",
    "\n",
    "cholera_data_admin2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to group by year and month, we'll focus on the extract the year value from the 'start_date'\n",
    "cholera_data_admin2[\"s_Date\"] = pd.to_datetime(\n",
    "    cholera_data_admin2[\"start_date\"], format=\"%m/%d/%Y\"\n",
    ")\n",
    "cholera_data_admin2[\"e_Date\"] = pd.to_datetime(\n",
    "    cholera_data_admin2[\"end_date\"], format=\"%m/%d/%Y\"\n",
    ")\n",
    "cholera_data_admin2[\"s_month\"] = cholera_data_admin2[\"s_Date\"].dt.month\n",
    "cholera_data_admin2[\"s_year\"] = cholera_data_admin2[\"s_Date\"].dt.year\n",
    "cholera_data_admin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data_admin2[\"months_in_duration\"] = cholera_data_admin2[\"e_Date\"].dt.to_period(\n",
    "    \"M\"\n",
    ").astype(int) - cholera_data_admin2[\"s_Date\"].dt.to_period(\"M\").astype(int)\n",
    "cholera_data_admin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data_admin2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data_admin2[\"outbreak_number\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_outbreaks = (\n",
    "    cholera_data_admin2.groupby([\"s_year\", \"ISO3\"]).max().loc[:, [\"outbreak_number\"]]\n",
    ")\n",
    "repeated_outbreaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_outbreak_bar = repeated_outbreaks.hvplot.bar(\n",
    "    x=\"ISO3\",\n",
    "    y=\"outbreak_number\",\n",
    "    by=\"s_year\",\n",
    "    cmap=\"Category20\",\n",
    "    stacked=True,\n",
    "    legend=\"right\",\n",
    "    width=800,\n",
    "    rot=90,\n",
    ")\n",
    "\n",
    "repeat_outbreak_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_trends = (\n",
    "    cholera_data_admin2.groupby(\"s_year\")\n",
    "    .sum()\n",
    "    .loc[:, [\"total_suspected_cases\", \"total_confirmed_cases\", \"total_deaths\"]]\n",
    ")\n",
    "overall_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_trends.hvplot.line(\n",
    "    x=\"s_year\",\n",
    "    y=[\"total_suspected_cases\", \"total_confirmed_cases\", \"total_deaths\"],\n",
    "    rot=90,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, if we zoom into the chart we find that `total_deaths` are sometimes greater than `total_confirmed_cases.` We should keep in mind, that in this line chart everything is aggregated by year (and not by country) so that this may be due to differences in quality of surveillance records across different areas. Regardless, it's something to keep in mind. \n",
    "\n",
    "In either case, we observe 2 distinct peaks of `total_suspected_cases`, one in 2012 and the other in 2016-2017 - the latter supported by an increase in `total_confirmed_cases.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping annual `total_suspected_cases` by country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_cases = (\n",
    "    cholera_data_admin2.groupby([\"s_year\", \"ISO3\", \"admin2\"])\n",
    "    .sum()[\"total_suspected_cases\"]\n",
    "    .reset_index()\n",
    ")\n",
    "yearly_cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging deeper into our first bar chart (see above) we will look at how the extent of `total_suspected_cases` is distributed over time and where reoccurrent outbreaks are occuring for consecutive years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hvplot to create a holoviews plot, but could also use holoviews itself\n",
    "\n",
    "bar_chart = yearly_cases.hvplot.bar(\n",
    "    x=\"ISO3\",\n",
    "    y=\"total_suspected_cases\",\n",
    "    by=\"s_year\",\n",
    "    cmap=\"Category20\",\n",
    "    stacked=True,\n",
    "    legend=\"right\",\n",
    "    width=800,\n",
    "    rot=90,\n",
    ")\n",
    "\n",
    "bar_chart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the stacked bar chart above we above observe that some countries see repeated outbreaks more often than others. Understanding this geographic distribution and if these countries are located nearer to each other will be helpful in understanding outbreak dynamics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which countries are most affected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_agg = (\n",
    "    cholera_data_admin2.groupby(\"ISO3\")\n",
    "    .sum()\n",
    "    .loc[:, [\"total_suspected_cases\", \"total_deaths\"]]\n",
    ")\n",
    "country_agg = country_agg.sort_values(\"total_suspected_cases\", ascending=False).head(10)\n",
    "\n",
    "country_agg.loc[:, [\"total_deaths\", \"total_suspected_cases\"]].iloc[::-1].hvplot.barh(\n",
    "    colormap=\"coolwarm_r\", stacked=False, legend=\"bottom_right\", height=600\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving geographic context\n",
    "\n",
    "Now we'll want to merge the yearly cases against the `admin0` boundaries so that we can map the distribution over time. Because both datasets share the 3-digit `ISO3` country code, we can merge them together on that column. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to add administrative boundaries to provide geospatial context. We'll use the ICPAC Administrative boundaries available [here](https://geoportal.icpac.net/layers/geonode:afr_g2014_2013_0/metadata_detail) and read them in with `geopandas`. This may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admin0_gdf = gpd.read_file(\n",
    "#     \"https://geoportal.icpac.net/geoserver/ows?service=WFS&version=1.0.0&request=GetFeature&typename=geonode%3Aafr_g2014_2013_0&outputFormat=json&srs=EPSG%3A4326&srsName=EPSG%3A4326\"\n",
    "# )\n",
    "# admin0_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admin1_gdf = gpd.read_file(\"https://geoportal.icpac.net/geoserver/ows?service=WFS&version=1.0.0&request=GetFeature&typename=geonode%3Aafr_g2014_2013_1&outputFormat=json&srs=EPSG%3A4326&srsName=EPSG%3A4326\")\n",
    "# admin1_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admin2_gdf = gpd.read_file(\"https://geoportal.icpac.net/geoserver/ows?service=WFS&version=1.0.0&request=GetFeature&typename=geonode%3Aafr_g2014_2013_2&outputFormat=json&srs=EPSG%3A4326&srsName=EPSG%3A4326\")\n",
    "# admin2_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "\n",
    "import aiohttp\n",
    "from geojson_pydantic import FeatureCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoawait asyncio\n",
    "\n",
    "\n",
    "async def fetch_bytes(session: aiohttp.ClientSession, url: str) -> bytes:\n",
    "    async with session.get(url) as response:\n",
    "        return await response.read()\n",
    "\n",
    "\n",
    "async def fetch_gadm_geojson(\n",
    "    session: aiohttp.ClientSession, iso3: str, adm: int\n",
    ") -> str:\n",
    "    geojson_filename = f\"gadm41_{iso3}_{adm}.json\"\n",
    "    zip_url = f\"https://geodata.ucdavis.edu/gadm/gadm4.1/json/{geojson_filename}.zip\"\n",
    "    zip_file = ZipFile(BytesIO(await fetch_bytes(session, zip_url)))\n",
    "\n",
    "    return zip_file.read(geojson_filename).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "async def fetch_gadm_geojsons(iso3s: list[str]) -> list[FeatureCollection]:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        requests = [fetch_gadm_geojson(session, iso3, 2) for iso3 in iso3s]\n",
    "\n",
    "        # Include raised exceptions in result list\n",
    "        results = await asyncio.gather(*requests, return_exceptions=True)\n",
    "        return [FeatureCollection.parse_raw(geojson) for geojson in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso3s = cholera_data_admin2[\"ISO3\"].unique().tolist()\n",
    "geojsons = await fetch_gadm_geojsons(iso3s)\n",
    "features = [feature for geojson in geojsons for feature in geojson]\n",
    "feature_collection = FeatureCollection(type=\"FeatureCollection\", features=features)\n",
    "admin2_gdf = gpd.GeoDataFrame.from_features(feature_collection).rename(\n",
    "    {\"GID_0\": \"ISO3\"}, axis=1\n",
    ")\n",
    "admin2_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process\n",
    "\n",
    "\n",
    "def append_admin2_match(score_cutoff: int):\n",
    "    def go(row):\n",
    "        iso3, admin2 = row.loc[[\"ISO3\", \"admin2\"]]\n",
    "        choices = admin2_gdf.query(f\"ISO3 == '{iso3}'\")[\"NAME_2\"]\n",
    "        triple = process.extractOne(admin2, choices, score_cutoff=score_cutoff)\n",
    "        name_2, score, *_ = triple or (\"\", 0)\n",
    "\n",
    "        return pd.concat([row, pd.Series({\"NAME_2\": name_2, \"score\": score})])\n",
    "\n",
    "    return go\n",
    "\n",
    "\n",
    "score_cutoff = 91\n",
    "\n",
    "matched_admin2s_df = (\n",
    "    cholera_data_admin2[[\"ISO3\", \"admin2\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values([\"ISO3\", \"admin2\"])\n",
    "    .apply(append_admin2_match(score_cutoff), axis=1)\n",
    "    .sort_values([\"score\"])\n",
    "    .query(\"NAME_2 != ''\")\n",
    ")\n",
    "\n",
    "matched_admin2s_df.to_csv(f\"matched_admin2s_{score_cutoff}.csv\", index=False)\n",
    "matched_admin2s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.geocoders\n",
    "import pycountry\n",
    "\n",
    "geolocator = geopy.geocoders.Nominatim(user_agent=\"cholera-dashboard\")\n",
    "geolocator.geocode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_cases_std = yearly_cases.merge(\n",
    "    matched_admin2s_df, how=\"left\", on=[\"ISO3\", \"admin2\"]\n",
    ")\n",
    "yearly_cases_std = yearly_cases_std[~yearly_cases_std[\"NAME_2\"].isna()]\n",
    "yearly_cases_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the coordinate reference system of the `admin0` administrative boundary dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admin0_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = pd.merge(admin0_gdf, yearly_cases, how=\"inner\", on=\"ISO3\")\n",
    "# merged_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did an `inner` merge, this will keep only those countries within the `admin0` dataset that _also_ have records in the cholera outbreak dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Cholera outbreaks from 2010-2019 at the national level\n",
    "\n",
    "Below, we use `plotly` to mapping cholera outbreaks over time. This is two get a better sense, geographically, of where repeated outbreaks are occuring and to visualize any spatial autocorrelation between them (i.e., are nations repeatedly experiencing outbreaks in closer proximity to each other?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_cases_std.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_snapshot = px.choropleth(\n",
    "    yearly_cases_std,\n",
    "    locations=\"NAME_2\",\n",
    "    color=\"total_suspected_cases\",\n",
    "    hover_name=\"NAME_2\",\n",
    "    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "    animation_frame=\"s_year\",\n",
    "    animation_group=\"NAME_2\",\n",
    "    range_color=[0, 100000],\n",
    "    geojson=feature_collection,\n",
    "    featureidkey=\"properties.NAME_2\",\n",
    ")\n",
    "\n",
    "yearly_snapshot.update_geos(scope=\"africa\")\n",
    "\n",
    "yearly_snapshot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a repeated central focal point around the Democratic Republic of the Congo (ISO3:`COD`). This is supported by the earlier bar chart we developed earlier highlighting that COD was the country that experienced the greatest amount of `total_suspected_cases.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important considerations\n",
    "Something to keep in mind for your future analyses: This dataset is of outbreaks in sub-Saharan Africa and is not explicitly an `endemic` Cholera dataset. \n",
    "\n",
    "* `Epidemic cholera` is generally sporadic and located further inland\n",
    "* `Endemic cholera` has a reoccuring indicence for consecutive years, often in coastal locations\n",
    "\n",
    "These two are not mutually exclusive, and both can take place in the same area - but for all intents and purposes of this PoC, we'll focus on this as an endemic cholera study (knowing that there will be other dynamics at play inland. \n",
    "\n",
    "Additionally, as the data above is aggregated at the national level, we are not able to make any assumptions about the sub-national geographic distribution of the outbreak (the outbreak could be near a coastline, or further inland). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is why we will want to explore at the subnational levels as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for machine learning purposes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explore the relationship between environmental covariates and cholera risk, we will convert cholera outbreaks into a `binary` data format based on the month of the outbreak's `start_date`. A value of `1` inidicates an outbreak in a particular month (_TBD: in x subnational adminstrative unit_) and a value of `0` indicating no outbreak present.  \n",
    "\n",
    "In retrospect, this may not even be required here - as we can more easily implement it as a pre-processing step on the predictor variables using `get_dummies()` just before the `train_test_split()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_data_admin2_std = matched_admin2s_df.merge(\n",
    "    cholera_data_admin2, how=\"left\", on=[\"ISO3\", \"admin2\"]\n",
    ")\n",
    "cholera_data_admin2_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(cholera_data_admin2_std[\"s_month\"], prefix=\"month\")\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the encoded df\n",
    "cholera_data_admin2_one_hot = cholera_data_admin2_std.join(one_hot)\n",
    "cholera_data_admin2_one_hot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On one-hot-encoding: \n",
    "* _Do we want to treat the binary variable as a reflection of when the outbreak started?_\n",
    "* _Or do we want one-hot-encode all months during the duration of the outbreak? In which case we need to revise the code above._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regards to the focus on endemic cholera, do we want to subset the dataset only to those areas within a specified distance (e.g., 100km) from the shore? This will reduce the confounding factors supplied in epidemic cholera further inland. **However**, it will also reduce the dataset we will have available for training and testing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
